{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908145e9",
   "metadata": {},
   "source": [
    "# Bag of Words: Traditional Aprroach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d85ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from khmernltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from google.colab import drive\n",
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653b8cd",
   "metadata": {},
   "source": [
    "### Function to clean and tokenize text (Preprocessing)\n",
    "- Remove spcial symbols\n",
    "- Tokenize by split the words with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c81d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and tokenize full article text\n",
    "def clean_and_tokenize(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Filter tokens: keep words, numbers, and common punctuation (.,!?)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        # Allow Khmer text (letters), numbers, spaces, and punctuation (.,!?)\n",
    "        if re.match(r'^[\\u1780-\\u17FF\"]+$', token):  # Khmer Unicode range + numbers and some punctuation\n",
    "            cleaned_tokens.append(token)\n",
    "\n",
    "    # Join the cleaned tokens and remove multiple spaces\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6823288",
   "metadata": {},
   "source": [
    "Load Data from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3ab919",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "file_names = []\n",
    "training_data = 'clean_data1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51348de6",
   "metadata": {},
   "source": [
    "- Load the data into documents list for later embedding step\n",
    "- Extract the Summary and Full Article and put in dataframe for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dff70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2025-06-18 19:51:55,326 | \u001b[1;32mINFO\u001b[0m | khmer-nltk | Loaded model from /Users/mac/Desktop/thesis/.venv/lib/python3.11/site-packages/khmernltk/word_tokenize/sklearn_crf_ner_10000.sav |\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file in sorted(os.listdir(training_data)):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(training_data, file)\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        summary = None\n",
    "        full_article = None\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip() == \"Summary:\":\n",
    "                summary = lines[i + 1].strip()\n",
    "            elif line.strip() == \"Full Article:\":\n",
    "                full_article = ''.join(lines[i + 1:]).strip()\n",
    "                break\n",
    "\n",
    "        if summary and full_article:\n",
    "            article_name = os.path.splitext(file)[0]  # Remove \".txt\"\n",
    "            documents.append({\n",
    "                'name': article_name,\n",
    "                'summary': clean_and_tokenize(summary),\n",
    "                'full_text': clean_and_tokenize(full_article),\n",
    "            })\n",
    "            file_names.append(file)\n",
    "        else:\n",
    "            print(f\"Missing summary or full article in {file}. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27868b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(documents)\n",
    "# df.to_csv('text_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdfabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>article_1</td>\n",
       "      <td>ស្ត្រី ជា បុគ្គល ដ៏ សំខាន់ ក្នុង រួមចំណែក ដំណើ...</td>\n",
       "      <td>កាលពី អតីតកាល កិច្ចការងារ និង មុខ តំណែង ក្នុង ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>article_100</td>\n",
       "      <td>អ្នកនាំពាក្យ ក្រសួង ការបរទេស អាម៉េរិក លោក កាលព...</td>\n",
       "      <td>ដំណើរទស្សនកិច្ច ទៅកាន់ ទីក្រុង សេអ៊ូល ជា ផ្នែក...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>article_1000</td>\n",
       "      <td>ព្រឹទ្ធសភា អាមេរិក នៅ ថ្ងៃទី ៩ ខែកុម្ភៈ បាន យល...</td>\n",
       "      <td>សវនាការ ដក តំណែង លើក ទី ពីរ ប្រឆាំង អតីត ប្រធា...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>article_10000</td>\n",
       "      <td>សកម្មភាព លក់ លំនៅឋាន ដែល មាន ផ្ទះល្វែង វីឡា ភ្...</td>\n",
       "      <td>របាយការណ៍ ដែល យោង តាម និយ័តករ អាជីវករ អចលន វត្...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>article_10001</td>\n",
       "      <td>ភ្នំពេញ៖ លោក វ៉ាង យី រដ្ឋមន្រ្តី ការបរទេស ចិន ...</td>\n",
       "      <td>ក្នុង ជំនួប នេះ លោក សុខ ចិន្តា សោភា បាន រំលេច ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>10020</td>\n",
       "      <td>article_9995</td>\n",
       "      <td>របាយការណ៍ ថ្មី មួយ ដែល សិក្សា ដោយ អង្គការ លីកា...</td>\n",
       "      <td>យោង តាម របាយការណ៍ នេះ អ្នក ខ្ចី ប្រាក់ ជាង ៣ យ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>10021</td>\n",
       "      <td>article_9996</td>\n",
       "      <td>៧ខែ មក នេះ កម្ពុជា ទទួលបាន ភ្ញៀវ ទេសចរ បរទេស ស...</td>\n",
       "      <td>ក្រសួង ទេសចរណ៍ បាន បញ្ជាក់ ថា បន្ទាប់ពី ថៃ ទេស...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>10022</td>\n",
       "      <td>article_9997</td>\n",
       "      <td>រយៈពេល ៧ខែ មក នេះ ការនាំចេញ របស់ កម្ពុជា ទៅកាន...</td>\n",
       "      <td>គឺជា កិច្ចព្រម ពៀង ភាពជាដៃគូ សេដ្ឋកិច្ច គ្រប់ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>10023</td>\n",
       "      <td>article_9998</td>\n",
       "      <td>ធនាគារ ជាតិ នៃ កម្ពុជា ប្រកាស ដាក់ ដេញថ្លៃ ប្រ...</td>\n",
       "      <td>បើ តាម សេចក្តីជូនដំណឹង របស់ ធនាគារ ជាតិ ការដេញ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>10024</td>\n",
       "      <td>article_9999</td>\n",
       "      <td>៧ខែ មក នេះ ការធ្វើ ពាណិជ្ជកម្ម រវាង កម្ពុជា ជា...</td>\n",
       "      <td>យោង តាម ទិន្នន័យ ពី អគ្គ នាយកដ្ឋាន គយ និង រដ្ឋ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10025 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           name  \\\n",
       "0               0      article_1   \n",
       "1               1    article_100   \n",
       "2               2   article_1000   \n",
       "3               3  article_10000   \n",
       "4               4  article_10001   \n",
       "...           ...            ...   \n",
       "10020       10020   article_9995   \n",
       "10021       10021   article_9996   \n",
       "10022       10022   article_9997   \n",
       "10023       10023   article_9998   \n",
       "10024       10024   article_9999   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      ស្ត្រី ជា បុគ្គល ដ៏ សំខាន់ ក្នុង រួមចំណែក ដំណើ...   \n",
       "1      អ្នកនាំពាក្យ ក្រសួង ការបរទេស អាម៉េរិក លោក កាលព...   \n",
       "2      ព្រឹទ្ធសភា អាមេរិក នៅ ថ្ងៃទី ៩ ខែកុម្ភៈ បាន យល...   \n",
       "3      សកម្មភាព លក់ លំនៅឋាន ដែល មាន ផ្ទះល្វែង វីឡា ភ្...   \n",
       "4      ភ្នំពេញ៖ លោក វ៉ាង យី រដ្ឋមន្រ្តី ការបរទេស ចិន ...   \n",
       "...                                                  ...   \n",
       "10020  របាយការណ៍ ថ្មី មួយ ដែល សិក្សា ដោយ អង្គការ លីកា...   \n",
       "10021  ៧ខែ មក នេះ កម្ពុជា ទទួលបាន ភ្ញៀវ ទេសចរ បរទេស ស...   \n",
       "10022  រយៈពេល ៧ខែ មក នេះ ការនាំចេញ របស់ កម្ពុជា ទៅកាន...   \n",
       "10023  ធនាគារ ជាតិ នៃ កម្ពុជា ប្រកាស ដាក់ ដេញថ្លៃ ប្រ...   \n",
       "10024  ៧ខែ មក នេះ ការធ្វើ ពាណិជ្ជកម្ម រវាង កម្ពុជា ជា...   \n",
       "\n",
       "                                               full_text  \n",
       "0      កាលពី អតីតកាល កិច្ចការងារ និង មុខ តំណែង ក្នុង ...  \n",
       "1      ដំណើរទស្សនកិច្ច ទៅកាន់ ទីក្រុង សេអ៊ូល ជា ផ្នែក...  \n",
       "2      សវនាការ ដក តំណែង លើក ទី ពីរ ប្រឆាំង អតីត ប្រធា...  \n",
       "3      របាយការណ៍ ដែល យោង តាម និយ័តករ អាជីវករ អចលន វត្...  \n",
       "4      ក្នុង ជំនួប នេះ លោក សុខ ចិន្តា សោភា បាន រំលេច ...  \n",
       "...                                                  ...  \n",
       "10020  យោង តាម របាយការណ៍ នេះ អ្នក ខ្ចី ប្រាក់ ជាង ៣ យ...  \n",
       "10021  ក្រសួង ទេសចរណ៍ បាន បញ្ជាក់ ថា បន្ទាប់ពី ថៃ ទេស...  \n",
       "10022  គឺជា កិច្ចព្រម ពៀង ភាពជាដៃគូ សេដ្ឋកិច្ច គ្រប់ ...  \n",
       "10023  បើ តាម សេចក្តីជូនដំណឹង របស់ ធនាគារ ជាតិ ការដេញ...  \n",
       "10024  យោង តាម ទិន្នន័យ ពី អគ្គ នាយកដ្ឋាន គយ និង រដ្ឋ...  \n",
       "\n",
       "[10025 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(documents)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7724c3",
   "metadata": {},
   "source": [
    "Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45eca6",
   "metadata": {},
   "source": [
    "Train Bag of Words to learn the words Then Embedd the entire documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['កក' 'កកក' 'កកករល' ... '៩៩៦' '៩៩៨' '៩៩៩ស']\n",
      "BoW Representation:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['full_text'])\n",
    "\n",
    "X = vectorizer.transform(df['full_text'])\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "# Print the Bag-of-Words matrix\n",
    "print(\"BoW Representation:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2c61f",
   "metadata": {},
   "source": [
    "Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3827fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khmer BoW Retrieval@10 Accuracy: 58.05\n",
      "841\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Retrieval@10 accuracy using summaries and 'name' as label\n",
    "correct_in_top10 = 0\n",
    "not_in = 0\n",
    "\n",
    "for _, row in test.iterrows():\n",
    "    summary_vec = vectorizer.transform([row['summary']])  # BoW vector for summary\n",
    "    similarities = cosine_similarity(summary_vec, X)[0]    # Similarity to all data docs\n",
    "    top_indices = similarities.argsort()[::-1][:10]        # Top 10 most similar\n",
    "\n",
    "    # Get top 10 predicted article names from training set\n",
    "    top_names = df.iloc[top_indices]['name'].values\n",
    "\n",
    "    # Check if the correct article name is among top 10\n",
    "    if row['name'] in top_names:\n",
    "        correct_in_top10 += 1\n",
    "    else:\n",
    "        not_in += 1\n",
    "\n",
    "accuracy = correct_in_top10 / len(test)\n",
    "print(f\"Khmer BoW Retrieval@10 Accuracy: {accuracy * 100:.2f}\")\n",
    "print(not_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38345cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['article_1881', 'article_644', 'article_1005', 'article_4919',\n",
       "       'article_6789', 'article_1477', 'article_4412', 'article_2925',\n",
       "       'article_6726', 'article_8540'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b24299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49302a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
